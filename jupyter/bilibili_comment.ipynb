{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip install lxml\n",
    "# %pip show lxml\n",
    "# import lxml\n",
    "# %pip install manimce\n",
    "%pip install langchain\n",
    "%pip install openai\n",
    "%pip install chromadb\n",
    "# %pip install youtube-transcript-api\n",
    "# %pip install tiktoken\n",
    "%pip install nest_asyncio\n",
    "%pip install pytube\n",
    "%pip install bilibili-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "# from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.document_loaders import BiliBiliLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ChatVectorDBChain, ConversationalRetrievalChain\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "  ChatPromptTemplate,\n",
    "  SystemMessagePromptTemplate,\n",
    "  HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "# 加载 youtube 频道\n",
    "# loader = YoutubeLoader.from_youtube_url('https://www.youtube.com/watch?v=Dj60HHy-Kqk',add_video_info=True)\n",
    "loader = BiliBiliLoader(\n",
    "    [\"https://www.bilibili.com/video/BV19P411R7rN/\"]\n",
    ")\n",
    "# 将数据转成 document\n",
    "documents = loader.load()\n",
    "print('load video ok')\n",
    "\n",
    "# 初始化文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "  chunk_size=1000,\n",
    "  chunk_overlap=20\n",
    ")\n",
    "\n",
    "# 分割 youtube documents\n",
    "documents = text_splitter.split_documents(documents)\n",
    "print('splitter text ok')\n",
    "# 初始化 openai embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "print('openai embeddings ok')\n",
    "# 将数据存入向量存储\n",
    "vector_store = Chroma.from_documents(documents, embeddings)\n",
    "# 通过向量存储初始化检索器\n",
    "retriever = vector_store.as_retriever()\n",
    "print('vector_store ok')\n",
    "system_template = \"\"\"\n",
    "Use the following context to answer the user's question.\n",
    "If you don't know the answer, say you don't, don't try to make it up. And answer in Chinese.\n",
    "-----------\n",
    "{context}\n",
    "-----------\n",
    "{chat_history}\n",
    "\"\"\"\n",
    "\n",
    "# 构建初始 messages 列表，这里可以理解为是 openai 传入的 messages 参数\n",
    "messages = [\n",
    "  SystemMessagePromptTemplate.from_template(system_template),\n",
    "  HumanMessagePromptTemplate.from_template('{question}')\n",
    "]\n",
    "\n",
    "# 初始化 prompt 对象\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "\n",
    "# 初始化问答链\n",
    "qa = ConversationalRetrievalChain.from_llm(ChatOpenAI(temperature=0.1,max_tokens=2048),retriever,qa_prompt=prompt)\n",
    "print('init ConversationalRetrievalChain ok')\n",
    "\n",
    "chat_history = []\n",
    "while True:\n",
    "  question = input('问题：')\n",
    "  # 开始发送问题 chat_history 为必须参数,用于存储对话历史\n",
    "  result = qa({'question': question, 'chat_history': chat_history})\n",
    "  chat_history.append((question, result['answer']))\n",
    "  print(result['answer'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
